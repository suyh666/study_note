

## **八、互联网服务之高可用性能集群**

### **8.1、计算机集群介绍**

==**集群是什么？**==

<img src="notes/image-20200319205410677-1603867038262.png" style="zoom: 33%;" />

**==为什么要集群？==**

<img src="notes/image-20200319205434767-1603867035894.png" style="zoom: 50%;" />

<img src="notes/image-20200319205452526-1603867004209.png" style="zoom:33%;" />

​																													天河一号服务器

<img src="notes/image-20200319205504415-1603867007290.png" style="zoom:33%;" />



<img src="notes/image-20200319205511555 (1)-1603867001588.png" style="zoom:33%;" />



### **8.2、nginx负载均衡集群介绍**

**==集群的分类==**

计算机集群按照功能可以分成如下几类

- 负载均衡集群
- 高可用性集群
- 高性能计算集群
- 网格计算

**==负载均衡集群==**

负载均衡集群为企业提供了更实用，性价比更高的系统架构方案。

负载均衡把很多客户集中的访问请求压力平均的分摊在计算机集群中进行处理。

每个节点承担一定的访问压力，并且实现请求在各个节点之间动态分配。

<img src="notes/image-20200319210008772-1603866998581.png" style="zoom: 50%;" />



<img src="D:/notes/image-20200319210111682.png" style="zoom:50%;" />

负载均衡集群运行时，一般是通过一个或者多个前端负载均衡器，将用户请求分发给后端的一组服务器上，从而达到整个系统的高性能和高可用性。

<img src="notes/image-20200319210306819-1603866995615.png" style="zoom:50%;" />

**==高可用性集群==**

高可用性集群指的是，集群中任意一个节点宕机的情况，该节点上所有的任务会自动转移到其他节点上，整个过程不会影响整个集群的运行。

当高可用集群中的一个节点系统发生故障时，运行着的集群服务器会迅速做出反应，把该系统的服务分配到集群中其他正在工作的机器上运行。

如果高可用性集群中主节点出现故障，那么宕机时间内将由备用节点代替它。

备用节点可以完全接管主节点（IP地址及其他资源），因此对于使用高可用性集群系统的用户是无感知的，不会影响用户访问。

<img src="notes/image-20200319215009929-1603866992963.png" style="zoom:50%;" />

高可用性集群的作用：

- 当一台机器宕机时，另一台机器接管宕机机器的IP资源和服务资源，继续提供服务。
- 用于例如负载均衡器的高可用，数据库的高可用



==**高性能计算集群**==

也成为并行计算，通常该集群系统用于解决复杂的科学问题，天气预报，石油勘探，核反应模拟等。

高性能计算机集群就如同一台超级计算机，该计算机系统由数十个至上万个独立的服务器组成。



### **8.3、软、硬件负载均衡介绍**

互联网企业常用的开源集群软件有：

- nginx
- lvs
- haproxy
- keepalived
- heartbeat

企业常用的商业集群硬件有：

- f5
- netscaler
- radware
- A10

淘宝、京东、新浪等公司用过Netscaler等负载均衡产品，以及F5产品。

<img src="notes/image-20200319220258714-1603866990457.png" style="zoom:50%;" />

<img src="notes/image-20200319220335317-1603866988271.png" style="zoom: 50%;" />



**==产品选择==**

- 当企业业务重要、技术力量又有欠缺，希望能够出钱购买产品得到优质服务的情况，可以直接购买硬件负载均衡设备，例如银行、证券、金融、汽车等非互联网大型行业。
- 对于门户网站来说，大部分企业选择用软硬件结合的方式，来分担单一产品的风险。
- 对于中小型企业，考虑成本问题，更希望通过运维人员通过软件技术解决集群问题。

比较而言，软件、硬件区别

- 硬件负载均衡成本高、性能强、安全性高、更稳定，但是不易于二次开发、扩展
- 开源负载均衡软件对运维人员的技术能力较高、如果开发能力强，对于开源软件二次开发是不错的选择，目前互联网公司更倾向于使用开源负载均衡设备。

**==如何选择开源负载均衡产品==**

中小互联网公司的服务器在用户并发量和总访问量还不是很大的情况下，建议首选Nginx负载均衡，其理由是：

- Nginx负载均衡配置简单
- 使用方便
- 安全稳定
- 社区活跃
- 使用人多居多
- 在淘宝公司的大流量业务得到了验证

另一个负载均衡产品是Haproxy同样很优秀，但是社区不如Nginx活跃。

当考虑使用Nginx进行负载均衡的时候，对其要进行高可用性设计，首选建议是用Keepalived软件，同样是因为配置简单、使用方便、安全稳定，另一款软件是Heartbeat（使用复杂，不推荐）

如果是大型互联网企业，负载均衡产品还会用`LVS+Keepalived`在网站架构前端做4层转发，后端再用`Nginx/Haproxy`做7层转发，最后是应用服务器。

**==Nginx负载均衡集群==**

负载均衡集群提供了一种廉价、有效、透明的方法扩展网络设备和服务器设备，集群能够提升计算机服务的负载能力、带宽、吞吐量，网络灵活性、高可用性等属性。

**==搭建负载均衡的背景==**

- 把单台计算机无法承受的大规模并发访问，大量的数据流量分摊给多台服务器设备进行处理，减少集中式的压力，减少用户的等待时间，提升用户体验。
- 单个重负担的运算压力分摊给多台机器节点并行处理，每个节点处理完毕后将结果汇总给用户，集群系统处理能力大幅度提升
- 高可用性负载均衡系统，保证了7*24小时的服务提供，同组集群内所有的计算机节点都提供相同的服务，单点故障也不会影响用户访问。

### **8.4、Nginx负载均衡实践1**

**==Nginx负载均衡实践==**

严格的来说，Nginx仅仅是作为Proxy反向代理的作用，因为这个反向代理的效果正是负载均衡的作用，所以称之为Nginx负载均衡。

**==负载均衡、反向代理区别？==**

普通的负载均衡软件，例如LVS，其表现的功能只是对请求数据包的转发、传递，其主要的DR模式功能是：

- 从负载均衡下的节点服务器观察，接收到的请求信息依然是`访问负载均衡器`的真实客户端的信息

然而反向代理的概念就不一样了：

- 反向代理是在接收到用户的请求后，再`代理用户`重新向代理下的节点服务器发送请求，在节点服务器上观察，此时的客户端已经是代理服务器了，而非是真实的客户端用户。

再次一句话概括：

- LVS等负载均衡是仅仅转发用户的请求数据包
- Nginx反向代理是接收到用户请求后，重新向后端节点发出新请求。

**==Nginx负载均衡部署==**

Nginx提供负载均衡的模块是：

```shell
ngx_http_proxy_module        proxy代理模块，用于把请求抛给后端的服务器节点，或是upstream服务器池
ngx_http_upstream_module    负载均衡模块，实现服务器的负载均衡节点配置，以及健康检查
```

Web服务器，直接面向用户，往往要承载大量并发请求，单台服务器难以负荷，我使用多台WEB服务器组成集群，前端使用Nginx负载均衡，将请求分散的打到我们的后端服务器集群中

实现负载的分发。那么会大大提升系统的吞吐率、请求性能、高容灾。



<img src="notes/image-20200319225813644-1603866984017.png" style="zoom:50%;" />

所有的请求统一发给Nginx负载均衡服务器，然后由负载均衡器通过调度算法再来请求Web01/02/03



### **8.5、Nginx负载均衡实践2**

**==服务器准备==**

准备四台VM虚拟机

- lb01，主负载均衡器，`192.168.37.200
- lb02，备负载均衡器（防止主节点故障），`192.168.37.201
- Web01，站点1，`192.168.37.202
- Web02，站点2（防止站点1故障），`192.168.37.203

**==软件准备==**

```shell
系统：CentOS Linux release 7.5.1804 (Core)
软件：nginx version: nginx/1.16.0
```

分别在四台机器上安装Nginx，因为Nginx提供如下功能

- 负载均衡
- web站点功能

```shell
1.安装依赖环境，重要
注意统一更换阿里云yum源!
yum install gcc patch libffi-devel python-devel  zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel openssl openssl-devel wget vim -y



2.编译安装nginx，编译安装能够统一管理目录，便于后期维护
mkdir -p /home/chaoge/tools
wget -P /home/chaoge/tools/ http://nginx.org/download/nginx-1.16.0.tar.gz

3.解压缩安装nginx
cd /home/chaoge/tools/
tar xf nginx-1.16.0.tar.gz
cd nginx-1.16.0
./configure --user=nginx --group=nginx --prefix=/opt/nginx-1.16.0 && make && make install

4.统一配置nginx环境变量
ln -s /opt/nginx-1.16.0/ /opt/nginx
检查软连接
ls -dl /opt/nginx

5.配置nginx环境变量
echo "PATH='/opt/nginx/sbin:/opt/mysql/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin'" >> /etc/profile

source /etc/profile

6.检查nginx环境变量
which nginx
```

![](notes/微信图片_20201017213351-1603866980006.png)



**==配置测试nginx的服务(web01,web02)==**

在Nginx的两台Web服务器上，进行操作（web01,web02），两台机器操作完全一致

注意可能要备份之前的配置文件

```shell
[root@web01 opt]# cp /opt/nginx/conf/nginx.conf{,.bak}
```

示例配置文件，修改为如下

```shell
[root@web01 opt]# cat /opt/nginx/conf/nginx.conf

http {
    include       mime.types;
    default_type  application/octet-stream;

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    #access_log  logs/access.log  main;

    sendfile        on;
    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    #access_log  logs/access.log  main;

    sendfile        on;
    #tcp_nopush     on;

    #keepalive_timeout  0;
    keepalive_timeout  65;

    #gzip  on;
    #第一个虚拟主机站点配置

    server {
        listen       80;
        server_name  www.dnf.cn;

        charset utf-8;

        access_log  logs/access_dnf.log  main;

        location / {
            root   html/dnf;
            index  index.html index.htm;
        }

    #第一个虚拟主机站点配置
    server {
        listen       80;
        server_name  www.cf.cn;

        charset utf-8;

        access_log  logs/access_cf.log  main;

        location / {
            root   html/cf;
            index  index.html index.htm;
        }
  }

```



创建测试站点的资源数据

```shell
1.创建数据文件夹
mkdir -p /opt/install/nginx1.18/html/{dnf,cf}

2.创建nginx静态网页文件
[root@web01 ~]# echo 'i am dnf web1:202'>/opt/install/nginx1.18/html/dnf/index.html
[root@web01 ~]# echo 'i am cf web1:202'>/opt/install/nginx1.18/html/cf/index.html
```

启动nginx，检测语法

```shell
[root@web01 opt]# nginx -t
nginx: the configuration file /opt/nginx-1.16.0//conf/nginx.conf syntax is ok
nginx: configuration file /opt/nginx-1.16.0//conf/nginx.conf test is successful
[root@web01 opt]#
[root@web01 opt]# nginx
[root@web01 ~]# netstat -tunpl|grep nginx
tcp        0      0 0.0.0.0:80              0.0.0.0:*               LISTEN      1682/nginx: master
```

配置本地linux的dns解析

```shell
[root@web01 opt]# echo "192.168.37.202 www.dnf.cn" >> /etc/hosts
[root@web01 opt]# echo "192.168.37.202 www.cf.cn" >> /etc/hosts
```

配置windows的hosts文件

```
C:\Windows\System32\drivers\etc
```

使用curl命令检测nginx站点

```shell
[root@web01 ~]# curl www.cf.cn
i am cf 202
[root@web01 ~]# curl www.dnf.cn
i am dnf 202
```

**同样的步骤，在web02上再执行一遍即可，注意区分两台机器的IP**

```shell
区别就在这里
[root@web01 opt]# echo "i am dnf web2:203" > /opt/install/nginx1.18/html/dnf/index.html
[root@web01 opt]# echo "i am cf web2:203" > /opt/install/nginx1.18/html/cf/index.html

[root@web02 nginx-1.16.0]# echo "192.168.37.203 www.dnf.cn www.cf.cn" >> /etc/hosts
```

**==实现一个简单的负载均衡==**

配置两台负载均衡的机器，也是一样的操作（lb01,lb02）

**配置lb01**

该负载均衡功能是由Nginx提供，修改nginx.conf如下

```shell
1.添加一个负载均衡池参数
# 定义web服务器地址池，也就是121,122两个节点
    upstream myweb{
  server  192.168.37.202 weight=1;  weight权重是1：1 
  server  192.168.37.203 weight=1;
    }



2.修改server{}虚拟主机参数
server {
        listen       80;
        server_name  www.syh.com;

        #charset koi8-r;

        #access_log  logs/host.access.log  main;

        location / {
                proxy_pass http://myweb;     #用于代理请求转发给地址池的ip
        }

        ...
}
```



**启动lb01负载均衡器**

```shell
[root@lb01 nginx-1.16.0]# nginx -t
nginx: the configuration file /opt/nginx-1.16.0/conf/nginx.conf syntax is ok
nginx: configuration file /opt/nginx-1.16.0/conf/nginx.conf test is successful

# 如果出现如下错误，表明当nginx还未启动，找不到pid文件
[root@lb01 nginx-1.16.0]# nginx -s reload
nginx: [error] invalid PID number "" in "/opt/nginx-1.16.0/logs/nginx.pid"

# 直接启动nginx即可
[root@lb01 nginx-1.16.0]# nginx
[root@lb01 nginx-1.16.0]#

# 检查负载均衡器
[root@lb01 nginx-1.16.0]# netstat -tunlp|grep 80
tcp        0      0 0.0.0.0:80              0.0.0.0:*               LISTEN      7500/nginx: mast
```



![](notes/image-20200320135606537-1603866974252.png)



**配置hosts文件**

```shell
1.添加一个本地测试域名
echo "192.168.37.200 www.lb1.cn" >> /etc/hosts
```



**访问负载均衡器，查看效果**

请求走到了负载均衡器，也就是nginx、进行代理转发请求

```shell
root@lb1 ~]# curl www.lb1.cn
i am dnf web01:192.168.27.202
[root@lb1 ~]# curl www.lb1.cn
i am dnf web02:192.168.37.203
[root@lb1 ~]# curl www.lb1.cn
i am dnf web01:192.168.27.202
[root@lb1 ~]# curl www.lb1.cn
i am dnf web02:192.168.37.203

#可看到请求一次走到web1、一次走到web2
```

![image-20201018160342299](notes/image-20201018160342299-1603866971518.png)



### **8.6、Nginx负载均衡之upstream**

**upstream模块详解**

<img src="notes/image-20200320150447914-1603866968988.png" style="zoom:50%;" />



**upstream模块介绍**

Nginx的负载均衡功能来自于其模块`ngx_http_upstream_module`模块，该模块支持的代理方式有：

- uwsgi_pass                  #和pyhton后台结合
- Fastcgi_pass               #和php后台结合
- proxy_pass                #用于转发http请求
- Memcached_pass
- ...

`ngx_http_upstream_module`模块允许Nginx定义一组或多组节点服务器，使用时可以通过`proxy_pass`代理方式，把用户请求发送到事先定于好的`upstream组`中。具体写法就是

```shell
upstream www_pools {
server x.x.x.x;
server x.x.x.x;
}

proxy_pass http://www_pools;
```

**完整的upstream配置案例**

```shell
upstream www_pools {
server 192.168.178.121;
server 192.168.178.122:80 weight=1 max_fails=1 fail_timeout=10s;
server 192.168.178.123:80 weight=10 max_fails=2 fail_timeout=20s backup;
server 192.168.178.124:80 wetight=10 max_fails=2 fail_timeout=20s backup;
}
```

**使用域名及socket的upstream配置**

```shell
upstream backend {
server backend1.example.com weight=5;
server backend2.example.com:8080;
server unix:/tmp/backend3;
server backend3.example.com:8080 backup;
}
```

**upstream模块参数**

```shell
# 参数解释
server是固定关键字，后面跟着服务器ip或是域名，默认是80端口，也可以指定端口
weight表示节点的权重，数字越大，分配的请求越多，注意nginx结尾的分号
max_fails Nginx尝试连接后端节点失败的次数，根据企业情况调整，默认是1
backup 其它所有的非backup机器down或者忙的时候，请求backup机器，实现热备效果。
fail_timeout 在max_fails定义的次数失败后，距离下次检查的间隔时间，默认10s
down 表示当前主机暂停，不参与负载均衡

upstream模块的内容应放于nginx.conf配置中的 http{}标签内
其默认调度算法是wrr(权重轮询，weighted round-robin)
```







### **8.8、Nginx均衡之调度算法**

**==upstream模块调度算法==**

调度算法一般分几类：

- 第一类是静态调度算法：负载均衡器根据自身设定的规则进行分配，不需要考虑后端节点的健康情况。例如轮询、加权轮询、哈希类型调度算法。
- 第二类是动态调度算法，负载均衡器会判断后端节点的当前状态，来决定是否分发请求。例如链接数最少的优先分发，响应时间短的优先分发，如least_conn、fail等都是动态调度。

**==rr轮询（round-robin）==**

按照请求顺序逐一分配给不同的后端节点服务器，如果后端节点宕机，宕机的服务器会被自动从地址池中剔除，新的请求会发给正常的服务器。

==**wrr（权重轮询）**==

给后端节点服务器增加权重，数值越大，优先获得客户端请求，可以以服务器配置来决定比例大小，从而解决新旧服务器的性能不均衡问题等。

```shell
upstream backend {
server 192.168.178.122 weight=1;
server 192.168.178.121 weight=2;
}
```

==**ip_hash**==

每个请求按客户端IP的hash结果分配，当新的请求到达，将其客户端IP通过哈希算法得到一个唯一值，在随后的客户端请求中，如果客户端的IP哈希值相等，该请求就会固定发给一台服务器。

该调度算法可以解决动态网页中的session共享问题。

注意了使用ip_hash不得再使用weight、backup两个参数，造成冲突了，即使写了也不生效。

```shell
upstream chaoge_backend {
ip_hash;
server 192.168.178.121;
server 192.168.178.122;

}
```

**==fail==**

该算法根据后端服务器节点的响应时间来分配，响应时间短的优先分配，该算法根据页面大小和加载时间长短进行负载均衡，nginx本身不支持fail形式，如果要支持该算法，必须下载nginx的`upstream_fail`模块

```shell
upstream chaoge_backend {
fair;
server 192.168.178.121;
server 192.168.178.122;
}
```

**==least_conn==**

该算法根据后端节点的链接数决定分配请求，哪个机器链接数少，就发给谁。

**==url_hash==**

和ip_hash类似，该算法根据客户端请求的URL信息进行hash得到唯一值，让每个URL固定的发给同一个后端服务器，后端服务器为`缓存服务器`效果最佳。

Nginx本身是不支持url_hash的，需要单独安装hash模块

url_hash(web缓存节点)和ip_hash(会话保持)功能类似。

```shell
upstream chaoge_backend {
server squid1:3128;
server squid:3128;
hash $request_uri;
hash_method crc32;
}
```



### **8.9、Nginx负载均衡之代理参数**

==**proxy_pass指令**==

proxy_pass指令属于`ngx_http_proxy_module`模块，此模块可以把请求转发到另一台服务器，在实际的反向代理工作中，会通过location功能指定的URL，然后把接收到的符合URL的请求通过proxy_pass参数抛给定义好的`upstream`地址池。

**proxy_pass案例**

案例1

```shell
在nginx.conf配置文件中定义

location /name/ {
proxy_pass http://127.0.0.1/remote/;
}

例如当请求URL是： http://192.168.178.121/name  ，会进入该locaiton的作用域，通过参数proxy_pass请求转发给了http://127.0.0.1/remote/
```

案例2

```shell
  location ~ .*\.php$ {
        proxy_pass http://www.example.cn$request_uri;
        proxy_set_header Host $proxy_host;    #获取客host请求头字段信息、如ip、域名等
        proxy_set_header X-Forwarded-For $remote_addr;   #获取真实客户端的ip
    }

所有请求以.php结尾的URL，进行转发
```

**proxy_pass参数**

| 参数                    | 作用解释                                                     |
| ----------------------- | ------------------------------------------------------------ |
| proxy_set_header        | 设置反向代理向后端发送的http请求头信息，如添加host主机头部字段，让后端服务器能够获取到真实客户端的IP信息等 |
| client_body_buffer_size | 指定客户端请求主体缓冲区大小                                 |
| proxy_connect_timeout   | 反向代理和后端节点连接的超时时间，也是建立握手后等待响应的时间 |
| proxy_send_timeout      | 表示代理后端服务器的数据回传时间，在规定时间内后端若数据未传完，nginx会断开连接 |
| proxy_read_timeout      | 设置Nginx从代理服务器获取数据的超时时间                      |
| proxy_buffer            | 设置缓冲区的数量大小                                         |





### **8.10、Nginx负载均衡之实战之多虚拟主机**



参考8.5nginx负载均衡实践2的环境搭建



```shell
【环境准备】
1.lb1:nginx代理服务器
2.web01：后台服务端1（安装了nginx)
3.web02: 后台服务端2（安装了nginx

【思路】
1.分别在web01、web02配置好两个多域名主机（主要配置多个server标签、静态文件）、web01的备份机器；
2.配置好lb1的反向代理转发配置；在本地解析好对应的域名关系

web01:
域名1：www.dnf.cn
域名2：www.cf.cn
web02:
域名1：www.dnf.cn
域名2：www.cf.cn

具体操作参考:8.5nginx负载均衡实践2的环境搭建
```

**Nginx负载均衡实战**

**定义一组www服务器池**

```
upstream myweb {
server 192.168.37.202 weight=1;
server 192.168.37.203 weight=1;
}
```

**配置虚拟主机实现代理**

注意这里是部分代码，修改了第一个server虚拟主机

```shell
 server {
        listen       80;
        server_name  www.chaoge.com;

        #charset koi8-r;

        #access_log  logs/host.access.log  main;

        location / {
        # 通过代理参数吧用户的请求转发给地址池中的服务器处理
                proxy_pass http://myweb;
        }    
}
```

**实测负载均衡效果**

```shell
[root@lb1 ~]# curl www.dnf.cn
i am dnf web01:192.168.27.202
[root@lb1 ~]# curl www.dnf.cn
i am dnf web02:192.168.37.203
[root@lb1 ~]# curl www.dnf.cn
i am dnf web01:192.168.27.202
[root@lb1 ~]# curl www.dnf.cn
i am dnf web02:192.168.37.203

```

从测试结果中，可以看出，请求逐一的分给两个节点服务器了，实现了请求分发功能。

但是问题是，为何看到的网页内容，一直都是dnf的内容，而非出现cf呢？

【图解答案】

<img src="notes/微信图片_20201018180843-1603866961600.png" style="zoom:50%;" />





### **8.11Nginx负载均衡之头部信息转发**



针对多个域名的代理转发、需要用到头部信息转发功能参数、代理机器将自己发送的请求携带请求头部信息（IP、域名）发送给节点服务器、明确指定域名的网站资源；返回给用户呈现

<img src="notes/微信图片_20201018175545-1603866959315.png" style="zoom: 67%;" />





**如何解决上述问题**

其根本原因是，用户访问域名时候确实是www.dnf.cn，请求首先是发给了Nginx反向代理服务器

问题是：

- 代理服务器(lb01)重新发起请求时，默认并没有在请求头里告诉节点服务器要找哪一个虚拟主机【www.dnf.cn】还是【www.cf.cn】
- 因此后端节点服务器接收到请求之后，并没有主机头信息，默认把请求发给了第一个虚拟主机去处理（以web01的nginx.conf中的配置，也就是dnf站点内容了）

解决办法：

- 在反向代理时候，添加主机头信息，明确告诉节点服务器找哪个虚拟主机

```shell
proxy_set_header Host $host;
```

在代理服务器向节点服务器发送HTTP请求头中添加host主机头信息后，若是后端服务器配置了多个虚拟主机，也就可以根据主机头的信息，来进行匹配决定发给哪一个虚拟主机【cf还是dnf】。

nginx.conf修改如下，修改location的配置

```shell
    server {
        listen       80;
        server_name  www.lb1.cn;

        #charset koi8-r;

        #access_log  logs/host.access.log  main;

        location / {
                proxy_pass http://myweb;
         # 添加该参数，在向后端发请求的时候，就会保留客户端的主机头信息，发给节点服务器
                proxy_set_header Host $host;
        }
}
```

最终效果，结果和域名就完全对应上了

```shell
[root@lb1 ~]# curl www.dnf.cn
i am dnf web01:192.168.27.202
[root@lb1 ~]# curl www.dnf.cn
i am dnf web02:192.168.37.203
[root@lb1 ~]# curl www.dnf.cn
i am dnf web01:192.168.27.202
[root@lb1 ~]# curl www.dnf.cn
i am dnf web02:192.168.37.203
[root@lb1 ~]# curl www.cf.cn
i am dnf web01:192.168.27.202
[root@lb1 ~]# curl www.cf.cn
i am dnf web02:192.168.37.203
[root@lb1 ~]# curl www.cf.cn
i am dnf web01:192.168.27.202
[root@lb1 ~]# curl www.cf.cn
i am dnf web02:192.168.37.203
```

![](notes/微信图片_20201018181551-1603866955925.png)



### **6.12网络爬虫与反向代理**

**反向代理&记录用户IP地址企业案例**

<img src="D:/notes/image-20200322220225936.png" style="zoom:50%;" />

对于互联网的资源，有时候程序员喜欢用爬虫程序去捉取

- 通过python网络爬虫脚本，大量获取文章、图片、视频等资源

那么对于网站管理员就不乐意了，爬虫程序频繁的网站网站获取资料，也就给管理员的服务器带来了额外的压力，那么运维人员一般会通过`Nginx的access.log`追踪用户的ip地址，发现异常、频繁的ip地址记录，就可以将其封禁，或者限制他的访问速率。

爬虫程序这时候如果发现自己的ip地址被限制了，他也会想些办法，逃避这个封禁，再次获取资料，那么他就会利用`代理IP`的方式再去爬取网站资料。

![](notes/image-20200322221604833-1603866953215.png)

这时候对于系统管理员也不乐意了，如果我只是封禁了代理的IP，我如何抓到`背后的那个坏人呢！（真实的客户端IP）`

**反向代理后的节点**

在反向代理或者代理IP这样的形式，访问服务器后，服务器捉到的都是反向代理机器的IP地址。

```shell
以我们之前的机器配置
web01 192.168.37.202
web02 192.168.37.203

lb1  192.168.37.200

lb1就是一台反向代理服务器（负载均衡的功能）
```

【演示反向代理功能】

![](notes/微信图片_20201018191203-1603866948322.png)

上述图片解读：

- 使用客户端机器web02，访问负载均衡器lb01（反向代理），看到了机器web01和web02的资料
- 在web服务器上检测客户端信息，发现客户端是192.168.37.200（这不是lb1吗）
- 我们明明用的是web02发出的请求

这就是反向代理的含义所在，用户请求发给了反向代理，反向代理再次发出了一个请求。

【如何解决这样的问题，捉到客户端的IP而非代理服务器呢？】



### **6.13nginx扑捉客户端真实IP**

**X-Forwarded-For**

在反向代理请求后端节点服务器的`请求头`中添加获取客户端IP的字段信息，然后在后端节点可以通过程序或者相关配置接收`X-Forwarded-For`传过来的真实用户的IP信息。

【lb01反向代理节点配置如下】

部分nginx.conf代码如下，注意重点修改的部分

```shell
http {
    include       mime.types;
    default_type  application/octet-stream;

# 定义web服务器地址池，也就是121,122两个节点
upstream myweb {
server 192.168.37.202 weight=1;
server 192.168.37.203 weight=1;
}

    server {
        listen       80;
        server_name  www.lb1.cn;

        #charset koi8-r;

        #access_log  logs/host.access.log  main;

        location / {
                proxy_pass http://myweb;
                proxy_set_header Host $host;
                # 添加此处代码即可，代理服务器向后端发送HTTP请求时，请求头中添加该参数信息，用于后端服务器程序、日志等接受真实用户的IP，而非是代理服务器的IP
                proxy_set_header X-Forwarded-For $remote_addr;
        }
}
}
```

重新加载lb01的nginx

```shell
[root@lb01 nginx-1.16.0]# nginx -s reload
```

特别注意，不仅要在代理服务器配置，添加获取真实IP的字段，还要再节点服务器中添加配置，接受用户真实的IP，配置日志格式等操作。

【修改节点服务器的nginx.conf】

部分代码修改如下，关注重点修改的部分

```shell
[root@web01 opt]# grep -Ev "^#|^$" /opt/nginx/conf/nginx.conf
worker_processes  1;
events {
    worker_connections  1024;
}
http {
    include       mime.types;
    default_type  application/octet-stream;
    sendfile        on;
    keepalive_timeout  65;
    gzip  on;

 # 重点修改这里的代码即可，添加结尾的参数$http_x_forwarded_for，即可在日志中获取客户端的真实IP
 # 注意access日志文件具体的路径，由下面虚拟主机的参数定义
log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                 '$status $body_bytes_sent "$http_referer" '
                  '"$http_user_agent" "$http_x_forwarded_for"';


server {
listen 80;
server_name bbs.chaoge.com;
location / {
    root html/bbs;
    index index.html;
}
# 注意这里的日志配置！！！一定要写和我一样的！！
access_log logs/access_bbs.log main;
}
server {
listen 80;
server_name www.chaoge.com;
location / {
    root html/www;
    index index.html index.htm;
}
# 注意这里的日志配置！！！一定要写和我一样的！！
access_log logs/access_www.log main;
}
}
```

重启节点服务器的nginx

```shell
[root@web01 opt]# nginx -s reload
```

【**测试效果一**】

配置步骤

```shell
1.在自己的电脑本地hosts文件中添加解析记录，超哥这里是mac的命令行终端
# windows的兄弟们，自行搜索hosts文件路径

yumac:~ root# tail -1 /etc/hosts
192.168.178.130 www.chaoge.com bbs.chaoge.com

2.在自己的本地电脑浏览器访问站点
```

![](notes/微信图片_20201018192227-1603866943172.png)

```shell
3.检查202节点的日志信息
[root@web01 logs]# tail -f /opt/install/nginx1.18/logs/access_dnf/log
192.168.37.200 - - [18/Oct/2020:19:21:52 +0800] "GET / HTTP/1.0" 200 30 "-" "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36" "192.168.37.1"


4.日志解析
192.168.37.200 显示的是远程访客的地址，也就是lb01负载均衡发来的请求
"192.168.37.1" 是通过X-Forwarded-For参数获取到的真实客户端的ip，也就是你笔记本的ip地址
```

![](notes/微信图片_20201018192501-1603866934482.png)

【**测试效果二**】

直接用curl命令测试访问

```shell
1.使用一台节点服务器去访问 负载均衡器
[root@web02 ~]# curl 192.168.37.200
i am dnf web01:192.168.27.202
[root@web02 ~]# curl 192.168.37.200
i am dnf web02:192.168.37.203
[root@web02 ~]# curl 192.168.37.200
i am dnf web01:192.168.27.202
[root@web02 ~]# curl 192.168.37.200
i am dnf web02:192.168.37.203


2.在一台节点服务器上查看访客日志
192.168.37.200 - - [18/Oct/2020:19:28:42 +0800] "GET / HTTP/1.0" 200 30 "-" "curl/7.29.0" "192.168.37.203"


最终通过日志，发现检测到了真实发请求的，其实是web02机器，ip为192.168.37.203
```

![image-20201018193040439](notes/image-20201018193040439-1603866931096.png)

**总结**

- nginx的accesslog日志，其日志格式里`$remote_addr`变量，表示远程客户端的IP地址（可能是代理IP地址）
- 其`$http_x_forwarded_for`变量，是接收了在反向代理中配置的`proxy_set_header X-Forwarded-For $remote_addr`，获取了用户真实的IP（躲在代理IP后）

当然这里的`X-Forwarded-For`并不是万能的，所谓道高一尺魔高一丈，对于代理的形式还有很多种。

| 代理参数                                                | 解释                                                         |
| ------------------------------------------------------- | ------------------------------------------------------------ |
| proxy_pass [http://server_pools](http://server_pools/); | 把用户的请求转发到反向代理定义的upstream地址池               |
| proxy_set_header Host $host;                            | 在代理服务器向后端节点机器发送HTTP请求时，加入host字段信息，可以用于当后端节点存在多个虚拟主机，且通过域名区分，可以通过该host参数，识别代理的主机是哪一个 |
| Proxy_set_header X-Forwarded-For $remote_addr;          | 代理服务器向后端节点发出请求时，添加该字段信息，能提供给后端节点机器，获取到真实客户端的IP地址 |



### **6.14nginx负载均衡之动静态分离**



**==反向代理参数优化==**

对于nginx众多的虚拟主机配置，如果写入一个文件里，难以维护，阅读，可以把参数配置，写入到单独的配置文件中，再通过nginx的`include`方式获取。

【不合适的写法】

部分nginx.conf配置如下

```shell
# 定义web服务器地址池，也就是121,122两个节点
upstream www_pools {
server 192.168.37.202 weight=1;
server 192.168.37.203 weight=2;
}

    server {
        listen       80;
        server_name  www.chaoge.com;
        default_type application/octet-stream;
        #charset koi8-r;

        #access_log  logs/host.access.log  main;

        location / {
                proxy_pass http://www_pools;
                # 代理参数都写这里，不易维护，观察
                proxy_set_header Host $host;
                                proxy_set_header X-Forwarded-For $remote_addr;
        }
}
```

【合适的写法】

```shell
/opt/nginx/conf/nginx.conf
# 定义web服务器地址池，也就是121,122两个节点
upstream www_pools {
server 192.168.178.121 weight=1;
server 192.168.178.122 weight=2;
}

    server {
        listen       80;
        server_name  www.chaoge.com;
        default_type application/octet-stream;
        #charset koi8-r;

        #access_log  logs/host.access.log  main;

        location / {
                proxy_pass http://www_pools;
                # 包含语法，读取该文件中的配置，加载到当前文件中
                include proxy.conf;
        }
}
```

生成规范的代理配置文件，注意和nginx.conf写在同一级目录

```shell
[root@lb01 conf]# cat proxy.conf
proxy_set_header Host $host;
proxy_set_header X-Forwarded-For $remote_addr;
proxy_connect_timeout 60;
proxy_send_timeout 60;
proxy_read_timeout 60;
proxy_buffer_size 4k;
proxy_buffers 4 32k;
proxy_busy_buffers_size 64k;
proxy_temp_file_write_size 64k;
```

详细的参数，解释，在官方文档可以查阅

```shell
http://nginx.org/en/docs/http/ngx_http_proxy_module.html
```



**反向代理企业案例**

**企业级动静分离案例**

该场景是，通过nginx实现动静分离，配置反向代理规则，实现动态请求和静态请求分别转发给不同的服务器解析，以解决网站性能、安全、用户体验等问题。

<img src="notes/image-20200323095205018-1603866926485.png" style="zoom:50%;" />

该架构图是企业常见的动静分离集群架构图，例如该网站域名是www.chaoge.com

- 当用户请求http://www.lb1.cn/upload/index.html，该形式的URL，代理服务器会将其转发到上游服务器`upload_pools`
- 当用户访问http://www.lb1.cn/static/index.html，该形式的URL，代理服务器会将其转发到静态服务器地址池`static_pools`
- 当用户访问http://www..lb1.cn/index.html，该形式的URL，也就是不包含指定的路径URL，代理服务器将其默认都转发给动态服务器池处理数据

**案例配置准备**

了解了需求，配置地址池即可，这里需要用到四台虚拟机，兄弟们可以自由定义

- web01
- web02
- web03
- 1b1

使用克隆的形式，创建虚拟机亦可

**明确配置**

| 主机  | IP，端口       | 测试地址                            | 显示内容 |
| ----- | -------------- | ----------------------------------- | -------- |
| web01 | 192.168.37.202 | http://www.lb1.cn/static/index.html |          |
| web02 | 192.168.37.203 | http://www.lb1.cn/upload/index.html |          |
| web03 | 192.168.37.201 | http://www..lb1.cn/index.html       |          |
| lb1   | 192.168.37.202 |                                     |          |

【配置静态服务器池】

```shell
http{
upstream web_static{
        server 192.168.37.202 weight=1;
}
}
```

【配置上传服务器池】

```shell
http{
upstream web_upload{
        server 192.168.37.203 weight=1;
}
}
```

【默认地址池，动态地址池，】

```shell
http{
upstream web_default{
        server 192.168.37.201 weight=1^
}
}
```

**实际配置思路**

【方案1】

使用nginx的location功能，匹配不同的URL（路径），请求分发给不同的服务器池

```shell
location /static/ {
    proxy_pass http://web_static;
    include proxy.conf;
}

location /upload/ {
proxy_pass http://web_upload;
include proxy.conf;
}

location / {
proxy_pass http://web_default;
include proxy.conf;
}
```

【方案2】

使用shell语句进行判断

```shell
if ($request_url ~* "^/static/(.*)$")
{
    proxy_pass http://web_static/$1;
}

if ($request_url ~* "^/upload/(.*)$")
{
    proxy_pass http://web_upload/$1;
}

location / {
    proxy_pass http://dweb_default;
    include proxy.conf;
}
```

**nginx实战配置**

```shell
1.编辑nginx.conf，修改添加如下代码
http{
# 定义三个地址池
upstream web_static {
        server 192.168.37.201 weight=1;
}

upstream web_upload{
        server 192.168.37.202 weight=1;
}

upstream web_default {
        server 192.168.37.203 weight=1;
}

# 定义虚拟主机
    server {
        listen       80;
        server_name  www.lb1.cn;
        

# 通过locaiton进行URL路径匹配
        location / {
                proxy_pass http://default_pools;
                include proxy.conf;
        }

        location /static/ {
                proxy_pass http://static_pools;
                include proxy.conf;
}

        location /upload/ {
                proxy_pass http://upload_pools;
                include proxy.conf;
}

}
```

准备好proxy.conf代理参数内容如下

```shell
[root@lb1 conf]# cat  proxy.conf

proxy_set_header Host $host;
proxy_set_header X-Forwarded-For $remote_addr;
proxy_connect_timeout 60;
proxy_send_timeout 60;
proxy_read_timeout 60;
proxy_buffer_size 4k;
proxy_buffers 4 32k;
proxy_busy_buffers_size 64k;
proxy_temp_file_write_size 64k;

```

**分别配置三个地址池**

**【修改静态服务器配置】**

**---这里很重要---**

```shell
创建一个static文件夹，因为请求转发给了此台机器，URL如下
www.lb1.cn/static/index.html  
# 必须在网页站点目录下，存在该static文件夹
[root@web01 logs]# mkdir -p /opt/install/nginx1.18/html/static
[root@web01 logs]# echo '我是static配置，请求已经解析成功'>>/opt/install/nginx1.18/html/static/index.html


修改nginx.conf支持中文
server {
listen 80;
server_name _;
charset utf-8;
location / {
        root html;
        index index.html index.htm;
}
#access_log logs/access_www.log main;
}
}



# 重启nginx
nginx -s reload
```

**【修改uploads服务器配置】**

这里其实访问的是`www.lb1.cn/upload`

因此必须得有upload目录

```shell
[root@web02 ~]# mkdir -p /opt/install/nginx1.18/html/upload
[root@web02 html]# echo '我是upload配置，请求已经解析成功'>>/opt/install/nginx1.18/html/upload/index.html


# 让nginx支持中文
server {
listen 80;
server_name _;
charset utf-8;
location / {
    root html;
    index index.html index.htm;
}
#access_log logs/access.log main;
}




# 重启nginx
nginx -s reload
```

**【配置默认的动态服务器】**

```shell
1.确保nginx.conf配置文件正确
server {
        listen       80;
        server_name  _;
        charset utf-8;
        
        #access_log  logs/host.access.log  main;
        
        location / {
            root   html;
            index  index.html index.htm;
        }
}

2.生成首页文件
[root@web03 html]# vim index.html 
[root@web03 html]# echo '我是default配置，请求已经解析成功'>index.html


3.启动nginx，或者重启 nginx -s reload
nginx
```

**测试访问结果**

使用浏览器访问，结果如下

【upload请求转发】

![](notes/微信图片_20201019142433-1603866919320.png)



【static请求转发】

![](notes/微信图片_20201019142417-1603866917116.png)



【default请求转发】

![](notes/微信图片_20201019142859-1603866914756.png)

### **6.15nginx七层负载均衡转发**

URL转发应用场景

根据HTTP的URL转发的场景，被称之为七层转发（应用层转发），然而LVS的负载均衡一般用于TCP的转发，也就被称之为4层转发。

利用Nginx的七层转发，可以实现动静分离，移动、PC端页面区分，交给不同的后端服务器处理，让用户得到更佳的访问体验。

**客户端设备匹配转发实战**

对于大多数网站，都是由区分移动端页面，PC端页面，对于用户不同的客户端设备，返回不同的页网站页面。

<img src="notes/微信图片_20201019151635-1603866911762.png" style="zoom:50%;" />

​																														【PC端】

<img src="notes/微信图片_20201019151741-1603866908138.png" style="zoom:50%;" />

​																																【移动端】

因此，为了让用户有更好的访问体验，就需要在服务器后端设立不同的服务器来满足不同的客户端访问。

例如，移动端客户访问网站，请求就转发给处理移动端页面的服务器，移动端还分为苹果、安卓、手机、ipad等不同的设备。

那么如何实现该方案呢

**基于4层负载均衡的转发**

四层转发就是`IP+PORT`的形式转发

在常规的4层负载均衡架构下，可以使用不同的域名来实现该需求，例如

- 人为分配，让移动端用户访问`m.chaoge.com`
- PC端用户访问`www.chaoge.com`
- 通过不同的域名来引导用户访问指定的后端服务器

<img src="notes/image-20200323113346122-1603866905642.png" style="zoom:50%;" />

但是这样的形式，用户需要记住不同的域名，用户肯定是不乐意的，体验较差

**基于7层的负载均衡**

在7层负载均衡下就不需要人为拆分域名了，移动端、PC端只需要一个`www.chaoge.com`域名即可。

方法就是通过获取用户请求中的客户端信息（来自于哪个浏览器，手机、ipad等等客户端），是通过`$http_user_agent`获取，根据该变量获取到的用户客户端信息，再决定交给哪一个后端服务器去处理。

这是企业常用的解决方案。

![image-20200323134758451](notes/image-20200323134758451.png)

**根据客户端转发实战**

我们可以模拟出当不同的浏览器，访问站点的时候，系统检测到的用户客户端信息

以下均是通过accesslog捉到的信息

**根据客户端转发实战**

我们可以模拟出当不同的浏览器，访问站点的时候，系统检测到的用户客户端信息

以下均是通过accesslog捉到的信息

**curl命令客户端**

```shell
[root@web01 conf]# curl 192.168.37.200
<meta charset=utf8>
我是default配置，请求已经解析成功


# 日志记录如下
192.168.37.202 - - [19/Oct/2020:15:26:54 +0800] "GET / HTTP/1.1" 200 67 "-" "curl/7.29.0"
```

**safari客户端**

```shell
192.168.178.130 - - [23/Mar/2020:02:00:36 -0400] "GET /static/ HTTP/1.0" 200 43 "-" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_3) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.0.5 Safari/605.1.15" "192.168.178.1"
```

**chrome客户端**

```shell
192.168.37.1 - - [19/Oct/2020:15:27:43 +0800] "GET /favicon.ico HTTP/1.1" 404 555 "http://192.168.37.200/" "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36"
```

**Nginx根据客户端信息转发配置**

**补充：location修饰符解释**

```shell
= 表示精确匹配。只有请求的url路径与后面的字符串完全相等时，才会命中。
~ 表示该规则是使用正则定义的，区分大小写。
~* 表示该规则是使用正则定义的，不区分大小写。
^~ 表示如果该符号后面的字符是最佳匹配，采用该规则，不再进行后续的查找。
利用shell语句进行逻辑判断

location / {
# 这里进行浏览器判断
if ($http_user_agent ~* "MSIE")
{
    proxy_pass http://static_pools;
}
if ($http_user_agent ~* "Chrome")
{
    proxy_pass http://upload_pools;
}

if ($http_user_agent ~* "Safari")
{
    proxy_pass http://static_pools;
}

proxy_pass http://default_pools;
include proxy.conf;

}
```

**Nginx实际配置**

修改nginx.conf如下，无须完整贴代码，看好修改了哪些配置即可

```shell
[root@lb01 conf]# grep -Ev "^#|^$" /opt/nginx/conf/nginx.conf
worker_processes  1;
events {
    worker_connections  1024;
}
http {
    include       mime.types;
    default_type  application/octet-stream;
    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';    
    sendfile        on;
    keepalive_timeout  65;
upstream www_pools {
server 192.168.178.121 weight=1;
server 192.168.178.122 weight=2;
}
upstream static_pools {
    server 192.168.178.121 weight=1;
}
upstream upload_pools {
    server 192.168.178.122 weight=1;
}
upstream default_pools {
    server 192.168.178.131 weight=1;
}
    server {
        listen       80;
        server_name  www.chaoge.com;
    default_type application/octet-stream;

# 修改如下代码
# 我们这里直接返回状态码，更直观看见区别，也可以编写proxy_pass
location / {

if ($http_user_agent ~* "Firefox") 
{   
        #proxy_pass http://static_pools;
        return 403; 
}  
if ($http_user_agent ~* "Chrome")
{
        #proxy_pass http://upload_pools;
        return 401;
}

if ($http_user_agent ~* "Safari")
{
        #proxy_pass http://static_pools;
        return 402;
}

proxy_pass http://default_pools;
include proxy.conf;

}


}
}
```

检测nginx语法，重启nginx

```shell
[root@lb01 conf]# nginx -t
nginx: the configuration file /opt/nginx-1.16.0/conf/nginx.conf syntax is ok
nginx: configuration file /opt/nginx-1.16.0/conf/nginx.conf test is successful
[root@lb01 conf]# nginx -s reload
```

**查看实际转发效果**

上述代码含义

- 当谷歌浏览器访问，返回401状态码
- 当火狐浏览器访问，返回403

![](notes/微信图片_20201019153820-1603866896100.png)

![](notes/微信图片_20201019154732-1603866893674.png)

可视化批量注释操作

```
1.vim 文件
2.ctrl+v进入可视化
3.光标选择注释的地方
4.输入大写I
5.在第一行数据添加#
6.按两下esc即可
```



**检测移动端客户端**

```shell
1.修改nginx.conf支持移动端检测，修改部分代码如下

location / {

if ($http_user_agent ~* "android")
{
return "400";
}

if ($http_user_agent ~* "iphone")
{
return "401";
}

proxy_pass http://default_pools;
include proxy.conf;

}


# 重启
nginx -s reload
```

直接通过curl命令，模拟客户端发起HTTP请求

```shell
[root@lb1 ~]# curl -A 'android' 192.168.37.200
<html>
<head><title>400 Bad Request</title></head>
<body>
<center><h1>400 Bad Request</h1></center>
<hr><center>nginx/1.18.0</center>
</body>
</html>
[root@lb1 ~]# curl -A 'iphone' 192.168.37.200
<html>
<head><title>401 Authorization Required</title></head>
<body>
<center><h1>401 Authorization Required</h1></center>
<hr><center>nginx/1.18.0</center>
</body>
</html>
```

**通过文件扩展名转发**

【方法一：通过location匹配】

1.通过检测用户发请求的文件后缀名来转发

```shell
location ~ .*.(gif|jpgjpeg|png|bmp|swf|css|js)$ {
        # proxy_pass http://static_pools;
        # include proxy.conf;
        return 503;
}

# 重启nginx -s reload



```

【方法二：通过shell语句判断】

```shell
if ($request_uri ~* ".*\.(php|php5)$")
{
    return 400
    #proxy_pass http://php_server_pols;
}

if ($request_uri ~* ".*\.(jsp|jsp*|do|do*)$")
{
	return 401
    #proxy_pass http://java_server_pools;
}
# 重启nginx -s reload



#测试结果
[root@lb1 conf]# curl  192.168.37.200/hah.php
<html>
<head><title>400 Bad Request</title></head>
<body>
<center><h1>400 Bad Request</h1></center>
<hr><center>nginx/1.18.0</center>
</body>
</html>

```

**nginx根据请求扩展名转发实践**

据此可以实现用户请求动静分离，例如图片，视频等请求静态资源服务器

php，jsp，等动态请求转发给动态服务器

```shell
# 修改nginx.conf添加如下代码

    server {
        listen       80;
        server_name  www.chaoge.com;
        default_type application/octet-stream;



          location / {

          if ($http_user_agent ~* "MSIE")
          {
                  #proxy_pass http://static_pools;
          }
          if ($http_user_agent ~* "Chrome")
          {
                  #proxy_pass http://upload_pools;
                  return 401;
          }

          if ($http_user_agent ~* "Safari")
          {
                  #proxy_pass http://static_pools;
                  return 402;
          }
          if ($http_user_agent ~* "android")
          {
          return "501";
          }

          if ($http_user_agent ~* "iphone")
          {
          return "502";
          }

          #proxy_pass http://default_pools;
          #include proxy.conf;

          }

          location ~ .*.(gif|jpg|jpeg|png|bmp|swf|css|js)$ {
                  # proxy_pass http://static_pools;
                  # include proxy.conf;
                  return 503;
          }

          location ~ .*.(php|php3|php5)$ {
                  return 504;
          }


          }

# 重启nginx
nginx -s reload
```

**客户端发出请求，验证配置**

![](notes/微信图片_20201019160742-1603866885040.png)

![](notes/微信图片_20201019160820-1603866878968.png)

看到这，我们利用文件后缀进行判断的实验也已经大功告成